#!/usr/bin/env python3
"""
Strands GraphBuilder ê¸°ë°˜ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸

ê¸°ì¡´ test_workflow.pyì™€ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤ë¡œ ìƒˆë¡œìš´ GraphBuilder ë²„ì „ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    uv run python test_workflow.py                                    # ë‹¨ì¼ í…ŒìŠ¤íŠ¸
    uv run python test_workflow.py --input examples/single/faq.json   # íŠ¹ì • ì…ë ¥ íŒŒì¼
    uv run python test_workflow.py --max-regen 2 --debug              # ì¬ìƒì„± + ë””ë²„ê·¸

ì˜µì…˜:
    --input FILE        ì…ë ¥ JSON íŒŒì¼ (ê¸°ë³¸: examples/single/default.json)
    --max-regen N       ìµœëŒ€ ì¬ìƒì„± íšŸìˆ˜ (ê¸°ë³¸: 1)
    --session-id ID     OTEL ì„¸ì…˜ ID ì§€ì •
    --debug             DEBUG ë¡œê·¸ ë ˆë²¨ í™œì„±í™” (í”„ë¡¬í”„íŠ¸ ì¶œë ¥)
    --dry-run           êµ¬ì¡° í™•ì¸ë§Œ (API í˜¸ì¶œ ì—†ìŒ)
"""

# =============================================================================
# ì˜ì¡´ì„±
# =============================================================================
import asyncio
import argparse
import json
import logging
import sys
from datetime import datetime
from pathlib import Path
from typing import List

sys.path.insert(0, str(Path(__file__).parent))

from src.models import TranslationUnit
from src.graph.builder import TranslationWorkflowGraphV2, TranslationWorkflowConfig
from src.utils.pricing import calculate_workflow_cost
from src.utils.result_formatter import format_workflow_result

# =============================================================================
# OTEL ì„¤ì • (ì„ íƒì )
# =============================================================================
try:
    from src.utils.strands_utils import observability_session
    OTEL_AVAILABLE = True
except ImportError:
    OTEL_AVAILABLE = False
    from contextlib import contextmanager
    @contextmanager
    def observability_session(**kwargs):
        yield {"session_id": kwargs.get("session_id") or "no-otel"}

# =============================================================================
# ì„¤ì •
# =============================================================================
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# ë¶ˆí•„ìš”í•œ ë¡œê·¸ ì–µì œ
logging.getLogger("botocore").setLevel(logging.WARNING)
logging.getLogger("urllib3").setLevel(logging.WARNING)
logging.getLogger("src.utils.strands_utils").setLevel(logging.WARNING)
logging.getLogger("strands.telemetry.metrics").setLevel(logging.WARNING)

RESULTS_DIR = Path(__file__).parent / "results"
EXAMPLES_DIR = Path(__file__).parent / "examples"


# =============================================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# =============================================================================
def log_header(*lines: str) -> None:
    """êµ¬ë¶„ì„ ìœ¼ë¡œ ê°ì‹¼ í—¤ë” ì¶œë ¥"""
    logger.info(f"\n{'='*60}")
    for line in lines:
        logger.info(line)
    logger.info("="*60)


def log_section(title: str) -> None:
    """ì„¹ì…˜ ì œëª© ì¶œë ¥"""
    logger.info(f"\n--- {title} ---")


def print_json_block(title: str, data: dict, summary_only: bool = False) -> None:
    """JSON ë¸”ë¡ ì¶œë ¥ (summary_only=Trueë©´ details ì œì™¸)"""
    print(f"\n{'='*60}")
    print(title)
    print("="*60)
    if summary_only and "details" in data:
        summary = {k: v for k, v in data.items() if k != "details"}
        print(json.dumps(summary, ensure_ascii=False, indent=2))
    else:
        print(json.dumps(data, ensure_ascii=False, indent=2))


def load_test_units(json_path: Path = None) -> List[TranslationUnit]:
    """JSON íŒŒì¼ì—ì„œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ"""
    if json_path is None:
        json_path = EXAMPLES_DIR / "single" / "default.json"

    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    return [TranslationUnit(**item) for item in data]


def get_timestamp() -> str:
    """íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±"""
    now = datetime.now()
    return now.strftime("%Y-%m-%d-%H-%M-%S") + f"-{now.microsecond // 1000:03d}"


def save_result(result: dict, run_dir: Path) -> Path:
    """ë‹¨ì¼ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
    key = result["unit"].key
    file_path = run_dir / f"{key}.json"

    output = format_workflow_result(result)

    with open(file_path, "w", encoding="utf-8") as f:
        json.dump(output, f, ensure_ascii=False, indent=2)

    return file_path


def log_single_result(result: dict) -> None:
    """ë‹¨ì¼ ë²ˆì—­ ê²°ê³¼ë¥¼ íŠ¸ë¦¬ í˜•íƒœë¡œ ì¶œë ¥"""
    m = result.get('metrics')
    total_ms = m.total_latency_ms if m else 0
    attempt = result.get('attempt_count', 1)
    state = result['workflow_state'].value

    # ìƒíƒœ ì•„ì´ì½˜
    icon = {"published": "âœ…", "pending_review": "âš ï¸", "rejected": "âŒ", "failed": "ğŸ’¥"}.get(state, "ğŸ”„")

    # í—¤ë”
    print(f"\n{icon} ì›Œí¬í”Œë¡œìš° ì™„ë£Œ ({total_ms/1000:.1f}s) [GraphBuilder V2]")

    # ë²ˆì—­
    if 'translation_result' in result:
        tr = result['translation_result']
        print(f"â”œâ”€ ë²ˆì—­: {tr.latency_ms}ms")
        print(f"â”‚   â””â”€ {tr.translation[:60]}{'...' if len(tr.translation) > 60 else ''}")

    # ì—­ë²ˆì—­
    if 'backtranslation_result' in result:
        bt = result['backtranslation_result']
        print(f"â”œâ”€ ì—­ë²ˆì—­: {bt.latency_ms}ms")
        print(f"â”‚   â””â”€ {bt.backtranslation[:60]}{'...' if len(bt.backtranslation) > 60 else ''}")

    # í‰ê°€
    if 'agent_results' in result:
        eval_latency = m.evaluation_latency_ms if m else 0
        print(f"â”œâ”€ í‰ê°€: {eval_latency}ms")
        agents = result['agent_results']
        for i, ar in enumerate(agents):
            is_last = (i == len(agents) - 1)
            prefix = "â”‚   â””â”€" if is_last else "â”‚   â”œâ”€"
            score_icon = "âœ“" if ar.score >= 4 else ("â–³" if ar.score == 3 else "âœ—")
            print(f"{prefix} {ar.agent_name}: {ar.score} {score_icon}")
            if ar.issues and ar.score < 4:
                issue_prefix = "â”‚       â””â”€" if is_last else "â”‚   â”‚   â””â”€"
                print(f"{issue_prefix} {ar.issues[0][:50]}...")

    # íŒì •
    if 'attempt_history' in result and len(result['attempt_history']) > 1:
        print(f"â””â”€ íŒì • ({attempt}íšŒ ì‹œë„)")
        history = result['attempt_history']
        for i, h in enumerate(history):
            is_last = (i == len(history) - 1)
            prefix = "    â””â”€" if is_last else "    â”œâ”€"
            scores_str = ", ".join(f"{k}:{v}" for k, v in h['scores'].items())
            print(f"{prefix} [ì‹œë„ {h['attempt']}] {h['verdict']} ({scores_str})")
            if h['message'] and is_last:
                print(f"        â””â”€ {h['message']}")
    elif 'gate_decision' in result:
        gd = result['gate_decision']
        print(f"â””â”€ íŒì •: {gd.verdict.value}")
        if gd.message:
            print(f"    â””â”€ {gd.message}")

    # ë¹„ìš©
    if m:
        cost = calculate_workflow_cost(m.token_usage)
        print(f"\nğŸ’° ë¹„ìš©: ${cost.total_cost:.4f} | í† í°: {m.token_usage['input']:,}+{m.token_usage['output']:,}")

    # ì˜¤ë¥˜
    if 'error' in result:
        print(f"\nâŒ ì˜¤ë¥˜: {result['error']}")


# =============================================================================
# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
# =============================================================================
async def test_single_translation(unit: TranslationUnit, config: TranslationWorkflowConfig) -> dict:
    """ë‹¨ì¼ ë²ˆì—­ í…ŒìŠ¤íŠ¸ (GraphBuilder V2)"""
    log_header(
        f"[GraphBuilder V2] í…ŒìŠ¤íŠ¸: {unit.key}",
        f"ì›ë¬¸: {unit.source_text[:50]}...",
        f"ëŒ€ìƒ ì–¸ì–´: {unit.target_lang}"
    )

    graph = TranslationWorkflowGraphV2(config)
    result = await graph.run(unit)

    log_single_result(result)

    # ê²°ê³¼ ì €ì¥
    timestamp = get_timestamp()
    run_dir = RESULTS_DIR / "single" / timestamp
    run_dir.mkdir(parents=True, exist_ok=True)

    file_path = save_result(result, run_dir)
    logger.info(f"\nğŸ“ ê²°ê³¼ ì €ì¥: {file_path}")

    # JSON ì¶œë ¥ (ìš”ì•½ë§Œ)
    output_dict = format_workflow_result(result)
    print_json_block("ğŸ“„ Result JSON:", output_dict, summary_only=True)

    return result


def test_dry_run(config: TranslationWorkflowConfig):
    """Dry run - ê·¸ë˜í”„ êµ¬ì¡° í™•ì¸ (API í˜¸ì¶œ ì—†ìŒ)"""
    log_header("[GraphBuilder V2] Dry Run: ê·¸ë˜í”„ êµ¬ì¡° í™•ì¸")

    print(f"\nğŸ“‹ ì„¤ì •:")
    print(f"  - max_regenerations: {config.max_regenerations}")
    print(f"  - num_candidates: {config.num_candidates}")
    print(f"  - enable_backtranslation: {config.enable_backtranslation}")
    print(f"  - timeout_seconds: {config.timeout_seconds}")
    print(f"  - max_node_executions: {config.max_node_executions}")

    print("\nğŸ“Š ì›Œí¬í”Œë¡œìš° íë¦„:")
    print("  TRANSLATE â†’ BACKTRANSLATE â†’ EVALUATE â†’ DECIDE")
    print("                                           â†“")
    print("               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print("               â†“                          â†“                          â†“")
    print("           FINALIZE                  REGENERATE                  FINALIZE")
    print("          (PASS/BLOCK)              (loop back)                 (ESCALATE)")

    print("\nğŸ“¦ ë…¸ë“œ ëª©ë¡:")
    nodes = ["translate", "backtranslate", "evaluate", "decide", "regenerate", "finalize"]
    for node in nodes:
        print(f"  - {node}")

    print("\nğŸ”— ì—£ì§€ ëª©ë¡:")
    edges = [
        ("translate", "backtranslate", None),
        ("backtranslate", "evaluate", None),
        ("evaluate", "decide", None),
        ("decide", "finalize", "should_finalize"),
        ("decide", "regenerate", "should_regenerate"),
        ("regenerate", "translate", None),
    ]
    for src, dst, cond in edges:
        cond_str = f" (condition: {cond})" if cond else ""
        print(f"  - {src} â†’ {dst}{cond_str}")

    print("\nâœ… Dry run ì™„ë£Œ")


# =============================================================================
# ë©”ì¸ ì§„ì…ì 
# =============================================================================
async def main():
    """ëª…ë ¹ì¤„ ì¸ìë¥¼ íŒŒì‹±í•˜ê³  ì ì ˆí•œ í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì‹¤í–‰"""
    parser = argparse.ArgumentParser(description="[GraphBuilder V2] ë²ˆì—­ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸")
    parser.add_argument("--input", type=str, help="ì…ë ¥ JSON íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--max-regen", type=int, default=1, help="ìµœëŒ€ ì¬ìƒì„± íšŸìˆ˜ (ê¸°ë³¸: 1)")
    parser.add_argument("--session-id", type=str, help="ì»¤ìŠ¤í…€ ì„¸ì…˜ ID")
    parser.add_argument("--debug", action="store_true", help="DEBUG ë¡œê·¸ ë ˆë²¨ í™œì„±í™” (í”„ë¡¬í”„íŠ¸ ì¶œë ¥)")
    parser.add_argument("--dry-run", action="store_true", help="êµ¬ì¡° í™•ì¸ë§Œ (API í˜¸ì¶œ ì—†ìŒ)")
    args = parser.parse_args()

    # DEBUG ëª¨ë“œ ì„¤ì •
    if args.debug:
        logging.getLogger("src.tools").setLevel(logging.DEBUG)
        logging.getLogger("src.graph").setLevel(logging.DEBUG)
        # strands ë‚´ë¶€ ë¡œê·¸ëŠ” ìˆ¨ê¹€
        logging.getLogger("strands").setLevel(logging.WARNING)

    # ì›Œí¬í”Œë¡œìš° ì„¤ì •
    config = TranslationWorkflowConfig(
        max_regenerations=args.max_regen,
        num_candidates=1,
        enable_backtranslation=True,
        timeout_seconds=120
    )

    # Dry run
    if args.dry_run:
        test_dry_run(config)
        return

    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
    input_path = Path(args.input) if args.input else None
    test_units = load_test_units(input_path)

    logger.info(f"OTEL: {'ENABLED' if OTEL_AVAILABLE else 'DISABLED'}")
    logger.info(f"Implementation: Strands GraphBuilder V2")

    # Observability ì„¸ì…˜ìœ¼ë¡œ ì‹¤í–‰
    with observability_session(
        session_id=args.session_id,
        workflow_name="translation-v2-single",
        metadata={"test_mode": "single", "version": "v2"}
    ) as session:
        logger.info(f"Session ID: {session['session_id']}")
        await test_single_translation(test_units[0], config)

    if OTEL_AVAILABLE:
        logger.info("View traces: https://console.aws.amazon.com/cloudwatch/home#gen-ai-observability")


if __name__ == "__main__":
    asyncio.run(main())
